{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "470/470 [==============================] - 1s 1ms/step - loss: 0.6663 - acc: 0.3064\n",
      "Epoch 2/30\n",
      "470/470 [==============================] - 0s 140us/step - loss: 0.1488 - acc: 0.8511\n",
      "Epoch 3/30\n",
      "470/470 [==============================] - 0s 72us/step - loss: 0.1488 - acc: 0.8511\n",
      "Epoch 4/30\n",
      "470/470 [==============================] - 0s 145us/step - loss: 0.1488 - acc: 0.8511\n",
      "Epoch 5/30\n",
      "470/470 [==============================] - 0s 234us/step - loss: 0.1488 - acc: 0.8511\n",
      "Epoch 6/30\n",
      "470/470 [==============================] - 0s 187us/step - loss: 0.1488 - acc: 0.8511\n",
      "Epoch 7/30\n",
      "470/470 [==============================] - 0s 104us/step - loss: 0.1487 - acc: 0.8511\n",
      "Epoch 8/30\n",
      "470/470 [==============================] - 0s 72us/step - loss: 0.1487 - acc: 0.8511\n",
      "Epoch 9/30\n",
      "470/470 [==============================] - 0s 142us/step - loss: 0.1487 - acc: 0.8511\n",
      "Epoch 10/30\n",
      "470/470 [==============================] - 0s 145us/step - loss: 0.1486 - acc: 0.8511\n",
      "Epoch 11/30\n",
      "470/470 [==============================] - 0s 145us/step - loss: 0.1498 - acc: 0.8447\n",
      "Epoch 12/30\n",
      "470/470 [==============================] - 0s 74us/step - loss: 0.1487 - acc: 0.8511\n",
      "Epoch 13/30\n",
      "470/470 [==============================] - 0s 142us/step - loss: 0.1485 - acc: 0.8511\n",
      "Epoch 14/30\n",
      "470/470 [==============================] - 0s 128us/step - loss: 0.1484 - acc: 0.8511\n",
      "Epoch 15/30\n",
      "470/470 [==============================] - 0s 166us/step - loss: 0.1485 - acc: 0.8511\n",
      "Epoch 16/30\n",
      "470/470 [==============================] - 0s 164us/step - loss: 0.1491 - acc: 0.8447\n",
      "Epoch 17/30\n",
      "470/470 [==============================] - 0s 166us/step - loss: 0.1480 - acc: 0.8489\n",
      "Epoch 18/30\n",
      "470/470 [==============================] - 0s 164us/step - loss: 0.1482 - acc: 0.8468\n",
      "Epoch 19/30\n",
      "470/470 [==============================] - 0s 140us/step - loss: 0.1477 - acc: 0.8511\n",
      "Epoch 20/30\n",
      "470/470 [==============================] - 0s 134us/step - loss: 0.1480 - acc: 0.8511\n",
      "Epoch 21/30\n",
      "470/470 [==============================] - 0s 77us/step - loss: 0.1475 - acc: 0.8511\n",
      "Epoch 22/30\n",
      "470/470 [==============================] - 0s 121us/step - loss: 0.1470 - acc: 0.8511\n",
      "Epoch 23/30\n",
      "470/470 [==============================] - 0s 168us/step - loss: 0.1467 - acc: 0.8511\n",
      "Epoch 24/30\n",
      "470/470 [==============================] - 0s 140us/step - loss: 0.1476 - acc: 0.8489\n",
      "Epoch 25/30\n",
      "470/470 [==============================] - 0s 72us/step - loss: 0.1471 - acc: 0.8511\n",
      "Epoch 26/30\n",
      "470/470 [==============================] - 0s 74us/step - loss: 0.1466 - acc: 0.8511\n",
      "Epoch 27/30\n",
      "470/470 [==============================] - 0s 147us/step - loss: 0.1473 - acc: 0.8511\n",
      "Epoch 28/30\n",
      "470/470 [==============================] - 0s 121us/step - loss: 0.1471 - acc: 0.8489\n",
      "Epoch 29/30\n",
      "470/470 [==============================] - 0s 132us/step - loss: 0.1471 - acc: 0.8489\n",
      "Epoch 30/30\n",
      "470/470 [==============================] - 0s 70us/step - loss: 0.1461 - acc: 0.8532\n",
      "470/470 [==============================] - 0s 344us/step\n",
      "\n",
      " 오차함수 : mean_squared_error, Accuracy: 0.8511\n"
     ]
    }
   ],
   "source": [
    "# 딥러닝을 구동하는데 필요한 케라스 함수를 불러옵니다.\n",
    "from keras.models import Sequential  # \n",
    "from keras.layers import Dense\n",
    "import numpy\n",
    "import tensorflow as tf\n",
    "\n",
    "# 실행할 때마다 같은 결과를 출력하는 부분 (역시 랜덤시드를 0으로 설정)\n",
    "seed = 0\n",
    "numpy.random.seed(seed)\n",
    "tf.set_random_seed(seed)\n",
    "\n",
    "# 데이터 불러오기\n",
    "Data_set = numpy.loadtxt(\"./ThoraricSurgery.csv\", delimiter=\",\") # delimiter는 구분자\n",
    "\n",
    "X = Data_set[:,0:17]  # X 환자기록 (1~18 칼럼) #### 1~17까지가 각각의 정보 = '속성'임 ####\n",
    "Y = Data_set[:,17]    # Y 수술결과 0 사망 1 죽음. 1이 더 많음  #### 예측하고자 하는 부분임. '클래스'라고 부름.\n",
    "\n",
    "# 구조 결정\n",
    "model = Sequential()  # 퍼셉트론 위에 숨겨진 퍼셉트론 층을 차곡차곡 추가하는 형태를 구현.\n",
    "model.add(Dense(30, input_dim=17, activation='relu'))  # 새로운 층이 만들어짐. # 각각의 층은 Dense라는 함수를 통해 구체적으로 구조가 결정.\n",
    "   # Dense 함수를 통해 해당 층에 몇 개의 노드를 만들 것인지를 숫자로 써줌. (30이라 되어있는 것은 해당 층에 30개의 노드를 만들겠다는 것)\n",
    "   # Input_dim은 입력 데이터로부터 몇 개의 값이 들어올지를 정함.\n",
    "   # keras는 입력층을 따로 만드는 것이 아닌. 첫 번째 은닉층에 input_dim을 적어줌으로써 첫 번째 Dense가 은닉층+입력층 역할 함.\n",
    "   # 은닉층의 각 노드는 17개의 입력 값(칼럼)으로부터 임의의 가중치를 가지고 각 노드로 전송되어 활성화 함수를 만난다.\n",
    "   # 활성화 함수를 거친 결과 값이 출력층으로 전달.\n",
    "  \n",
    "    \n",
    "model.add(Dense(1, activation='sigmoid'))   # 두개의 층을 가진 모델을 만든 것임.   # 마지막 층이므로 결과를 출력하는 '출력층' 이 된 것.\n",
    "   # 출력 값을 하나로 정해서 보여줘야 하므로 출력층의 노드 수는 1개. 활성화 함수를 한번 더 거쳐서 최종 출력 값 나옴.\n",
    "\n",
    "# 실행. 컴파일 부분은 앞부분서 지정한 모델이 효과적으로 구현될 수 있게 여러가지 환경을 설정해 주면서 컴파일 하는 .\n",
    "model.compile(loss='mean_squared_error', optimizer = 'adam', metrics=['accuracy']) \n",
    "   #  오차함수를 '평균 제곱 오차 함수'사용. \n",
    "   # 최적화를 위해서 아담을 사용.\n",
    "   # metrics는 모델이 컴파일 될 때 모델 수행 결과를 나타내게 설정하는 부분. # 정확도 측정하기 위해 사용되는 테스트 샘플을 학습 과정에서 제외시킴으로써 과적적합 문제를 방지.\n",
    "    \n",
    "    \n",
    "################################\n",
    "# 교차 엔트로피는 주로 분류 문제에서 많이 사용되는데, 특별히 예측 값이 참과 거짓 둘중하나인 형식에서는 '이항 교차 엔트로피' 사용.\n",
    "# # 실제로 아래에선 loss='mean_squared_error' 부분을 'binary_crossentropy'로 고쳐준 결과 아래와 같이 결괏값이 소폭 상승\n",
    "# 470/470 [==============================] - 0s 157us/step - loss: 0.4394 - acc: 0.8553\n",
    "# 케라스에서 사용하는 대표적인 오차함수 계열은 다음과 같다\n",
    "##  평균제곱계열 : mean_squared_error / mean_absolute_error / mean_absolute_percentage_error / mean_squared_logarithmic_error\n",
    "### 교차 엔트로피 계열 : categorical_crossentropy (범주형, 일반적인 분류) / binary_crossentropy (두 개의 클래스 중에 예측 시)\n",
    "################################\n",
    "    \n",
    "model.fit(X,Y, epochs=30, batch_size=10)\n",
    "    # 가로 한 줄에 해당하는 각 환자의 정보를 각각 '샘플' 이라고 한다.\n",
    "    # batch_size는 전체 470개의 샘플을 10개씩 끊어서 집어넣으라는 뜻.\n",
    "\n",
    "# 결과출력\n",
    "print(\"\\n 오차함수 : mean_squared_error, Accuracy: %.4f\" % (model.evaluate(X,Y)[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "470/470 [==============================] - 1s 1ms/step - loss: 6.3973 - acc: 0.4191 \n",
      "Epoch 2/30\n",
      "470/470 [==============================] - 0s 149us/step - loss: 1.2920 - acc: 0.8021\n",
      "Epoch 3/30\n",
      "470/470 [==============================] - 0s 174us/step - loss: 0.9804 - acc: 0.8064\n",
      "Epoch 4/30\n",
      "470/470 [==============================] - 0s 172us/step - loss: 0.7834 - acc: 0.7936\n",
      "Epoch 5/30\n",
      "470/470 [==============================] - 0s 81us/step - loss: 0.6569 - acc: 0.7787\n",
      "Epoch 6/30\n",
      "470/470 [==============================] - 0s 162us/step - loss: 0.5195 - acc: 0.8213\n",
      "Epoch 7/30\n",
      "470/470 [==============================] - 0s 170us/step - loss: 0.4811 - acc: 0.8340\n",
      "Epoch 8/30\n",
      "470/470 [==============================] - 0s 164us/step - loss: 0.4599 - acc: 0.8447\n",
      "Epoch 9/30\n",
      "470/470 [==============================] - 0s 130us/step - loss: 0.4652 - acc: 0.8489\n",
      "Epoch 10/30\n",
      "470/470 [==============================] - 0s 81us/step - loss: 0.4502 - acc: 0.8426\n",
      "Epoch 11/30\n",
      "470/470 [==============================] - 0s 196us/step - loss: 0.4340 - acc: 0.8511\n",
      "Epoch 12/30\n",
      "470/470 [==============================] - 0s 170us/step - loss: 0.4325 - acc: 0.8511\n",
      "Epoch 13/30\n",
      "470/470 [==============================] - 0s 83us/step - loss: 0.4364 - acc: 0.8511\n",
      "Epoch 14/30\n",
      "470/470 [==============================] - 0s 159us/step - loss: 0.4740 - acc: 0.8383\n",
      "Epoch 15/30\n",
      "470/470 [==============================] - 0s 145us/step - loss: 0.4303 - acc: 0.8511\n",
      "Epoch 16/30\n",
      "470/470 [==============================] - 0s 147us/step - loss: 0.4439 - acc: 0.8489\n",
      "Epoch 17/30\n",
      "470/470 [==============================] - 0s 138us/step - loss: 0.4484 - acc: 0.8489\n",
      "Epoch 18/30\n",
      "470/470 [==============================] - 0s 89us/step - loss: 0.4858 - acc: 0.8511\n",
      "Epoch 19/30\n",
      "470/470 [==============================] - 0s 181us/step - loss: 0.4564 - acc: 0.8511\n",
      "Epoch 20/30\n",
      "470/470 [==============================] - 0s 153us/step - loss: 0.4301 - acc: 0.8511\n",
      "Epoch 21/30\n",
      "470/470 [==============================] - 0s 168us/step - loss: 0.4220 - acc: 0.8511\n",
      "Epoch 22/30\n",
      "470/470 [==============================] - 0s 149us/step - loss: 0.4315 - acc: 0.8489\n",
      "Epoch 23/30\n",
      "470/470 [==============================] - 0s 83us/step - loss: 0.4356 - acc: 0.8511\n",
      "Epoch 24/30\n",
      "470/470 [==============================] - 0s 157us/step - loss: 0.4376 - acc: 0.8468\n",
      "Epoch 25/30\n",
      "470/470 [==============================] - 0s 179us/step - loss: 0.4299 - acc: 0.8511\n",
      "Epoch 26/30\n",
      "470/470 [==============================] - 0s 172us/step - loss: 0.4771 - acc: 0.8383\n",
      "Epoch 27/30\n",
      "470/470 [==============================] - 0s 85us/step - loss: 0.4514 - acc: 0.8426\n",
      "Epoch 28/30\n",
      "470/470 [==============================] - 0s 123us/step - loss: 0.4840 - acc: 0.8298\n",
      "Epoch 29/30\n",
      "470/470 [==============================] - 0s 168us/step - loss: 0.4398 - acc: 0.8553\n",
      "Epoch 30/30\n",
      "470/470 [==============================] - 0s 187us/step - loss: 0.4066 - acc: 0.8426\n",
      "470/470 [==============================] - 0s 330us/step\n",
      "\n",
      " 오차함수 : binary_crossentropy, Accuracy: 0.8489\n"
     ]
    }
   ],
   "source": [
    "# 딥러닝을 구동하는데 필요한 케라스 함수를 불러옵니다.\n",
    "from keras.models import Sequential  # \n",
    "from keras.layers import Dense\n",
    "import numpy\n",
    "import tensorflow as tf\n",
    "\n",
    "# 실행할 때마다 같은 결과를 출력하는 부분 (역시 랜덤시드를 0으로 설정)\n",
    "seed = 0\n",
    "numpy.random.seed(seed)\n",
    "tf.set_random_seed(seed)\n",
    "\n",
    "# 데이터 불러오기\n",
    "Data_set = numpy.loadtxt(\"./ThoraricSurgery.csv\", delimiter=\",\") # delimiter는 구분자\n",
    "\n",
    "X = Data_set[:,0:17]  # X 환자기록 (1~18 칼럼) #### 1~17까지가 각각의 정보 = '속성'임 ####\n",
    "Y = Data_set[:,17]    # Y 수술결과 0 사망 1 죽음. 1이 더 많음  #### 예측하고자 하는 부분임. '클래스'라고 부름.\n",
    "\n",
    "# 구조 결정\n",
    "model = Sequential()  # 퍼셉트론 위에 숨겨진 퍼셉트론 층을 차곡차곡 추가하는 형태를 구현.\n",
    "model.add(Dense(30, input_dim=17, activation='relu'))  # 새로운 층이 만들어짐. # 각각의 층은 Dense라는 함수를 통해 구체적으로 구조가 결정.\n",
    "   # Dense 함수를 통해 해당 층에 몇 개의 노드를 만들 것인지를 숫자로 써줌. (30이라 되어있는 것은 해당 층에 30개의 노드를 만들겠다는 것)\n",
    "   # Input_dim은 입력 데이터로부터 몇 개의 값이 들어올지를 정함.\n",
    "   # keras는 입력층을 따로 만드는 것이 아닌. 첫 번째 은닉층에 input_dim을 적어줌으로써 첫 번째 Dense가 은닉층+입력층 역할 함.\n",
    "   # 은닉층의 각 노드는 17개의 입력 값(칼럼)으로부터 임의의 가중치를 가지고 각 노드로 전송되어 활성화 함수를 만난다.\n",
    "   # 활성화 함수를 거친 결과 값이 출력층으로 전달.\n",
    "  \n",
    "    \n",
    "model.add(Dense(1, activation='sigmoid'))   # 두개의 층을 가진 모델을 만든 것임.   # 마지막 층이므로 결과를 출력하는 '출력층' 이 된 것.\n",
    "   # 출력 값을 하나로 정해서 보여줘야 하므로 출력층의 노드 수는 1개. 활성화 함수를 한번 더 거쳐서 최종 출력 값 나옴.\n",
    "\n",
    "# 실행. 컴파일 부분은 앞서 지정한 모델이 효과적으로 구현될 수 있게 여러가지 환경을 설정해 주면서 컴파일 하는 부분.\n",
    "model.compile(loss='binary_crossentropy', optimizer = 'adam', metrics=['accuracy']) \n",
    "   #  오차함수를 '평균 제곱 오차 함수'사용. \n",
    "   # 최적화를 위해서 아담을 사용.\n",
    "   # metrics는 모델이 컴파일 될 때 모델 수행 결과를 나타내게 설정하는 부분. # 정확도 측정하기 위해 사용되는 테스트 샘플을 학습 과정에서 제외시킴으로써 과적적합 문제를 방지.\n",
    "  \n",
    "model.fit(X,Y, epochs=30, batch_size=10)\n",
    "    # 가로 한 줄에 해당하는 각 환자의 정보를 각각 '샘플' 이라고 한다.\n",
    "    # batch_size는 전체 470개의 샘플을 10개씩 끊어서 집어넣으라는 뜻.\n",
    "\n",
    "# 결과출력\n",
    "print(\"\\n 오차함수 : binary_crossentropy, Accuracy: %.4f\" % (model.evaluate(X,Y)[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
