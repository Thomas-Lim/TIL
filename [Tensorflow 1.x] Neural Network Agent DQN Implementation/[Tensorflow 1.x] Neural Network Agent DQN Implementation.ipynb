{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Tensorflow 1.x] 신경망 Agent DQN 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "import pywrap_tensorflow\n",
    "import _distributor_init\n",
    "import _mklinit\n",
    "\n",
    "from game import Game\n",
    "from model import DQN\n",
    "\n",
    "tf.app.flags.DEFINE_boolean(\"train\", False, \"학습모드. 게임을 화면에 보여주지 않습니다.\")\n",
    "FLAGS = tf.app.flags.FLAGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 하이퍼파라미터 설정\n",
    "MAX_EPISODE = 10000   # 게임을 10000회 학습\n",
    "TARGET_UPDATE_INTERVAL = 1000   # 목표신경망을 1000회마다 한번씩 갱신\n",
    "TRAIN_INTERVAL = 4   # 4회 마다 한번씩 학습\n",
    "OBSERVE = 100  # 일정수준의 학습 데이터가 쌓이기 전에는 학습하지 않고 지켜보기만 해라. 100번의 프레임이 지난 뒤부터 학습."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 게임에 필요한 설정\n",
    "NUM_ACTION = 3 #행도, 0:좌, 1:유지, 2:우\n",
    "SCREEN_WIDTH = 6\n",
    "SCREEN_HEIGHT = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#텐서플로 세션과 게임 객체, DQN 모델 객체 생성\n",
    "\n",
    "def train():\n",
    "    print('뇌세포 깨우는 중...')\n",
    "    sess = tf.Session()\n",
    "    \n",
    "    game = Game(SCREEN_WIDTH, SCREEN_HEIGHT, show_game=False)\n",
    "    brain = DQN(sess, SCREEN_WIDTH, SCREEN_HEIGHT, NUM_ACTION)\n",
    "    \n",
    "    # 학습 결과 저장 및 상태 확인 코드\n",
    "    rewards = tf.placeholder(tf.float32, [None])\n",
    "    tf.summary.scalar('avg.reward/ep.', tf.reduce_mean(rewards))   # 한 판마다 얻는 점수를 저장하고 확인\n",
    "    \n",
    "    saver = tf.train.Saver()   # 학습결과를 저정하기 위한 saver와 텐서플로 세션\n",
    "    sess.run(tf.global_variables_initializerializer())\n",
    "    \n",
    "    writer = tf.summary.FileWriter('logs', sess.graph)  # 로그를 저장과 학습상태 확인 위한 텐서 설정\n",
    "    summary_merged = tf.summary.merge_all()\n",
    "    \n",
    "    # 목표 신경망 초기화\n",
    "    brain.update_target_network()\n",
    "    # 행동을 선택할 때 DQN을 이용할 시점을 정한다. 학습 초반에는 항상 같은 값만 내놓는 DQN이지만, 일정 시간 지나기 전에는 행동을 무작위로 선택해야 한다.\n",
    "    # 이를 위해 게임 진행중에 epsilon 값을 줄여나가는 코드를 넣는다.\n",
    "    epsilon = 1.0  # 입실론 값은 무작위 상태코드 값인데, 게임 진행(학습진행) 할 수록 점점 사용 비율이 줄어든다.\n",
    "    \n",
    "    # 점수 저장 배열 초기화\n",
    "    time_step =0 \n",
    "    total_reward_list = []\n",
    "    \n",
    "    # 여기서부터 진짜 게임 진행하고 학습시키는 부분. 10000회 실행하며, 매 게임을 시작하기 전에 초기화\n",
    "    #################################################################################################\n",
    "    \n",
    "    for episode in range(MAX_EPISODE):\n",
    "        terminal = False\n",
    "        total_reward = 0\n",
    "        \n",
    "        state = game.reset()   # 이 상태를 DQN의 초기 상태값에 넣어준다.\n",
    "        brain.init_state(state)  # 화면크기 구성\n",
    "        \n",
    "    # 원래 DQN은 픽셀값들을 상태값으로 받지만, 여기서 사용하는 게임모듈에서는 해당 위치에 사각형이 있는지 없는지를 1과 0으로만 받는다.\n",
    "    # 아래는 게임 한번 진행\n",
    "        while not terminal:\n",
    "            if np.random_read() < epsilon:\n",
    "                action = random.randrange(NUM_ACTION)\n",
    "            else:\n",
    "                action = brain.get_action()\n",
    "                \n",
    "            if episode > OBSERVE:\n",
    "                opsilon -= 1 / 1000\n",
    "                \n",
    "            state, reward, terminal = game.step(action)\n",
    "            total_reward += reward\n",
    "            \n",
    "            brain.remember(state, action, reward, terminal) # 현재 상태를 신경망 객체에 기억시킵니다. 이 기억한 현재 상태를 이용해 다음 상태에서 취할 행동을 정합니다.\n",
    "            \n",
    "            if time_step > OBSERVE and time_step & TRAIN_INTERVAL == 0:\n",
    "                brain.train()\n",
    "            \n",
    "            if time_step % TARGET_UPDATE_INTERVAL == 0:\n",
    "                brain.update_target_network()\n",
    "            \n",
    "            time_step += 1\n",
    "            \n",
    "            print('게임횟수: %d 점수: %d' % (episode + 1, total_reward))\n",
    "            \n",
    "            total_reward_list.append(total_reward)\n",
    "            \n",
    "            if episode % 10 == 0:\n",
    "                summary = sess.run(summary_merged, feed_dict={rewards: total_reward_list})\n",
    "                writer.add_summary(summary, time_step)\n",
    "                total_reward_list = []\n",
    "                \n",
    "            if episode % 100 == 0:\n",
    "                saveer.save(sess, 'model1/dqn.ckpt', global_step=time_step)\n",
    "                \n",
    "############ 여기까지가 학습을 시키는 에이전트 코드 ############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 결과 실행 함수 작성 \n",
    "# tf.train.Saver()로 저장해둔 모델을 읽어와서 생성한다.\n",
    "\n",
    "def replay():\n",
    "    print('뇌세포 깨우는 중...')\n",
    "    sess = tf.Session()\n",
    "    \n",
    "    game = Game(SCREEN_WIDTH, SCREEN_HEIGHT, show_game=True)\n",
    "    brain = DQN(sess, SCREEN_WIDTH, SCREEN_HEIGHT, NUM_ACTION)\n",
    "    \n",
    "    saver = tf.train.Saver()\n",
    "    ckpt = tf.train.get_checkpoint_state('model')\n",
    "    saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "    \n",
    "    # 게임 진행 부분\n",
    "    \n",
    "    for episode in range(MAX_EPISODE):\n",
    "        terminal = False\n",
    "        total_reward = 0\n",
    "        \n",
    "        state = game.reset()\n",
    "        brain.init_state(state)\n",
    "        \n",
    "        while not terminal:\n",
    "            action = brain.get_action()\n",
    "            \n",
    "            state, reward, terminal = game.step(action)\n",
    "            total_reward += reward\n",
    "            \n",
    "            brain.remember(state, action, reward, terminal)\n",
    "            \n",
    "            time.sleep(0.3)\n",
    "            \n",
    "        print('게임횟수: %d 점수: %d' % (episode + 1, total_reward))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "뇌세포 깨우는 중...\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\fu\\Documents\\3minuts_TensorFlow-Tutorials-master\\12 - DQN\\model.py:33: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0904 23:13:56.615809  7136 deprecation_wrapper.py:119] From C:\\Users\\fu\\Documents\\3minuts_TensorFlow-Tutorials-master\\12 - DQN\\model.py:33: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\fu\\Documents\\3minuts_TensorFlow-Tutorials-master\\12 - DQN\\model.py:47: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0904 23:13:56.619808  7136 deprecation_wrapper.py:119] From C:\\Users\\fu\\Documents\\3minuts_TensorFlow-Tutorials-master\\12 - DQN\\model.py:47: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\fu\\Documents\\3minuts_TensorFlow-Tutorials-master\\12 - DQN\\model.py:48: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.keras.layers.Conv2D` instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0904 23:13:56.621806  7136 deprecation.py:323] From C:\\Users\\fu\\Documents\\3minuts_TensorFlow-Tutorials-master\\12 - DQN\\model.py:48: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.keras.layers.Conv2D` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\fu\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0904 23:13:56.625805  7136 deprecation.py:506] From C:\\Users\\fu\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "I0904 23:13:58.479652  7136 utils.py:141] NumExpr defaulting to 4 threads.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0904 23:13:59.512014  7136 lazy_loader.py:50] \n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\fu\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\layers\\python\\layers\\layers.py:1634: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0904 23:13:59.514011  7136 deprecation.py:323] From C:\\Users\\fu\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\layers\\python\\layers\\layers.py:1634: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\fu\\Documents\\3minuts_TensorFlow-Tutorials-master\\12 - DQN\\model.py:51: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0904 23:13:59.764858  7136 deprecation.py:323] From C:\\Users\\fu\\Documents\\3minuts_TensorFlow-Tutorials-master\\12 - DQN\\model.py:51: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\fu\\Documents\\3minuts_TensorFlow-Tutorials-master\\12 - DQN\\model.py:63: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0904 23:14:00.102648  7136 deprecation_wrapper.py:119] From C:\\Users\\fu\\Documents\\3minuts_TensorFlow-Tutorials-master\\12 - DQN\\model.py:63: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\fu\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0904 23:14:00.461423  7136 deprecation.py:323] From C:\\Users\\fu\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from model\\dqn.ckpt-1708830\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0904 23:14:00.467420  7136 saver.py:1280] Restoring parameters from model\\dqn.ckpt-1708830\n"
     ]
    }
   ],
   "source": [
    "# 스크립트 학습용으로 실행할 지, 학습된 결과로 게임을 진행할 지 선택하는 부분\n",
    "# 터미널이나 명령 프롬프트에서 스크립트를 실행할 때 train 옵션을 받아 정하게 함\n",
    "\n",
    "\n",
    "def main(_):\n",
    "    if FLAGS.train:\n",
    "        train()\n",
    "    else:\n",
    "        replay()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    tf.app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
